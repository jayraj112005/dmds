# Import necessary libraries
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules

# Step 1: Read the dataset
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
iris_data = pd.read_csv(url, names=column_names)

# Display the first few rows of the dataset
print("Iris Dataset:")
print(iris_data.head())

# Step 2: Convert dataset to transactional format
# For simplicity, we will create binary indicators for the features
# You can adjust the threshold for binarization based on your needs
iris_data['sepal_length'] = pd.cut(iris_data['sepal_length'], bins=[4.0, 5.0, 6.0, 8.0], labels=["short", "medium", "long"])
iris_data['sepal_width'] = pd.cut(iris_data['sepal_width'], bins=[1.0, 2.5, 3.5, 5.0], labels=["narrow", "medium", "wide"])
iris_data['petal_length'] = pd.cut(iris_data['petal_length'], bins=[0.0, 1.5, 4.5, 7.0], labels=["small", "medium", "large"])
iris_data['petal_width'] = pd.cut(iris_data['petal_width'], bins=[0.0, 0.5, 1.5, 2.5], labels=["thin", "medium", "thick"])

# Now we convert the dataset to a one-hot encoded format
transaction_data = pd.get_dummies(iris_data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])

# Step 3: Apply the Apriori algorithm
frequent_itemsets = apriori(transaction_data, min_support=0.1, use_colnames=True)

# Step 4: Generate the association rules
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.0)

# Display the results
print("\nFrequent Itemsets:")
print(frequent_itemsets)

print("\nAssociation Rules:")
print(rules)
